{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReservoirConfig:\n",
    "    \"\"\"Configuration for the pendulum reservoir\"\"\"\n",
    "    sampling_rate: int = 10  # κ in the paper\n",
    "    cycles_per_sample: int = 20  # N in the paper\n",
    "    memory_length: int = 100  # m in the paper, for temporal tasks\n",
    "    damping: float = 0.05  # k in the paper\n",
    "    length: float = 1.0  # l in the paper\n",
    "    dt: float = 0.01  # integration time step\n",
    "    force_min: float = 1.0  # minimum force amplitude\n",
    "    force_max: float = 2.0  # maximum force amplitude\n",
    "    base_frequency: float = 1.0  # ω in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PendulumReservoir:\n",
    "    def __init__(self, config: ReservoirConfig):\n",
    "        self.config = config\n",
    "        self.g = 9.81  # gravitational acceleration\n",
    "        \n",
    "    def _integrate_pendulum(self, \n",
    "                           x0: torch.Tensor, \n",
    "                           v0: torch.Tensor, \n",
    "                           force_amp: torch.Tensor, \n",
    "                           force_freq: torch.Tensor,\n",
    "                           n_steps: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Integrate pendulum equations using RK4 method\"\"\"\n",
    "        dt = self.config.dt\n",
    "        x, v = x0, v0\n",
    "        \n",
    "        for _ in range(n_steps):\n",
    "            # RK4 integration\n",
    "            k1x = v\n",
    "            k1v = (-self.g/self.config.length * torch.sin(x) \n",
    "                   - self.config.damping * v \n",
    "                   + force_amp * torch.sign(torch.sin(force_freq * _ * dt)))\n",
    "            \n",
    "            k2x = v + 0.5 * dt * k1v\n",
    "            k2v = (-self.g/self.config.length * torch.sin(x + 0.5 * dt * k1x)\n",
    "                   - self.config.damping * (v + 0.5 * dt * k1v)\n",
    "                   + force_amp * torch.sign(torch.sin(force_freq * (_ + 0.5) * dt)))\n",
    "            \n",
    "            k3x = v + 0.5 * dt * k2v\n",
    "            k3v = (-self.g/self.config.length * torch.sin(x + 0.5 * dt * k2x)\n",
    "                   - self.config.damping * (v + 0.5 * dt * k2v)\n",
    "                   + force_amp * torch.sign(torch.sin(force_freq * (_ + 0.5) * dt)))\n",
    "            \n",
    "            k4x = v + dt * k3v\n",
    "            k4v = (-self.g/self.config.length * torch.sin(x + dt * k3x)\n",
    "                   - self.config.damping * (v + dt * k3v)\n",
    "                   + force_amp * torch.sign(torch.sin(force_freq * (_ + 1) * dt)))\n",
    "            \n",
    "            x = x + (dt/6) * (k1x + 2*k2x + 2*k3x + k4x)\n",
    "            v = v + (dt/6) * (k1v + 2*k2v + 2*k3v + k4v)\n",
    "            \n",
    "        return x, v\n",
    "\n",
    "    def get_reservoir_state(self, \n",
    "                           input_value: torch.Tensor, \n",
    "                           encoding: str = 'amplitude') -> torch.Tensor:\n",
    "        \"\"\"Get reservoir state for a single input value\"\"\"\n",
    "        # Initialize pendulum state\n",
    "        x0 = torch.zeros_like(input_value)\n",
    "        v0 = torch.zeros_like(input_value)\n",
    "        \n",
    "        # Set force parameters based on encoding\n",
    "        if encoding == 'amplitude':\n",
    "            force_amp = self.config.force_min + (self.config.force_max - self.config.force_min) * input_value\n",
    "            force_freq = torch.full_like(input_value, self.config.base_frequency)\n",
    "        else:  # frequency encoding\n",
    "            force_amp = torch.full_like(input_value, self.config.force_max)\n",
    "            force_freq = self.config.force_min + (self.config.force_max - self.config.force_min) * input_value\n",
    "            \n",
    "        # Calculate number of steps needed\n",
    "        period = 2 * np.pi / self.config.base_frequency\n",
    "        steps_per_cycle = int(period / self.config.dt)\n",
    "        total_steps = steps_per_cycle * self.config.cycles_per_sample\n",
    "        \n",
    "        # Get sampled states\n",
    "        states = []\n",
    "        for i in range(self.config.cycles_per_sample):\n",
    "            x, v = self._integrate_pendulum(x0, v0, force_amp, force_freq, steps_per_cycle)\n",
    "            for _ in range(self.config.sampling_rate):\n",
    "                states.append(x)\n",
    "            x0, v0 = x, v\n",
    "            \n",
    "        return torch.stack(states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReservoirComputer:\n",
    "    def __init__(self, config: ReservoirConfig, temporal: bool = False):\n",
    "        self.config = config\n",
    "        self.reservoir = PendulumReservoir(config)\n",
    "        self.temporal = temporal\n",
    "        self.W = None  # Output weights\n",
    "        \n",
    "    def _get_state_matrix(self, \n",
    "                         inputs: torch.Tensor, \n",
    "                         encoding: str = 'amplitude') -> torch.Tensor:\n",
    "        \"\"\"Convert input sequence to state matrix\"\"\"\n",
    "        states = []\n",
    "        for input_value in inputs:\n",
    "            state = self.reservoir.get_reservoir_state(input_value, encoding)\n",
    "            if self.temporal:\n",
    "                states.append(state)\n",
    "                if len(states) > self.config.memory_length:\n",
    "                    states.pop(0)\n",
    "            else:\n",
    "                states = [state]\n",
    "                \n",
    "        if self.temporal:\n",
    "            # Weight states by recency\n",
    "            weights = torch.linspace(0, 1, len(states))\n",
    "            state_matrix = torch.stack([w * s for w, s in zip(weights, states)])\n",
    "        else:\n",
    "            state_matrix = states[0]\n",
    "            \n",
    "        return state_matrix.flatten(1)\n",
    "    \n",
    "    def fit(self, \n",
    "            inputs: torch.Tensor, \n",
    "            targets: torch.Tensor, \n",
    "            encoding: str = 'amplitude') -> None:\n",
    "        \"\"\"Train the reservoir computer\"\"\"\n",
    "        state_matrix = self._get_state_matrix(inputs, encoding)\n",
    "        # Use pseudo-inverse for regression\n",
    "        self.W = torch.linalg.pinv(state_matrix) @ targets\n",
    "        \n",
    "    def predict(self, \n",
    "                inputs: torch.Tensor, \n",
    "                encoding: str = 'amplitude') -> torch.Tensor:\n",
    "        \"\"\"Make predictions using trained weights\"\"\"\n",
    "        if self.W is None:\n",
    "            raise ValueError(\"Model must be trained first\")\n",
    "        state_matrix = self._get_state_matrix(inputs, encoding)\n",
    "        return state_matrix @ self.W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage for Task I: Learning a polynomial\n",
    "def task_1():\n",
    "    # Configure reservoir\n",
    "    config = ReservoirConfig()\n",
    "    rc = ReservoirComputer(config, temporal=False)\n",
    "    \n",
    "    # Generate training data\n",
    "    x = torch.linspace(-3, 3, 50)\n",
    "    y = (x - 3) * (x - 2) * (x - 1) * x * (x + 1) * (x + 2) * (x + 3)\n",
    "    \n",
    "    # Normalize inputs to [0, 1]\n",
    "    x_norm = (x - x.min()) / (x.max() - x.min())\n",
    "    \n",
    "    # Train reservoir\n",
    "    rc.fit(x_norm, y)\n",
    "    \n",
    "    # Generate test data\n",
    "    x_test = torch.linspace(-3, 3, 10)\n",
    "    x_test_norm = (x_test - x.min()) / (x.max() - x.min())\n",
    "    y_pred = rc.predict(x_test_norm)\n",
    "    \n",
    "    return x_test, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage for Task II: Lorenz attractor reconstruction\n",
    "def task_2():\n",
    "    def lorenz(state, dt, sigma=10, rho=28, beta=8/3):\n",
    "        x, y, z = state\n",
    "        dx = sigma * (y - x)\n",
    "        dy = x * (rho - z) - y\n",
    "        dz = x * y - beta * z\n",
    "        return torch.tensor([dx, dy, dz]) * dt\n",
    "    \n",
    "    # Generate Lorenz data\n",
    "    dt = 0.01\n",
    "    n_steps = 5000\n",
    "    state = torch.tensor([1.0, 1.0, 1.0])\n",
    "    x_series = []\n",
    "    z_series = []\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        state = state + lorenz(state, dt)\n",
    "        x_series.append(state[0].item())\n",
    "        z_series.append(state[2].item())\n",
    "    \n",
    "    x_series = torch.tensor(x_series)\n",
    "    z_series = torch.tensor(z_series)\n",
    "    \n",
    "    # Normalize data\n",
    "    x_norm = (x_series - x_series.min()) / (x_series.max() - x_series.min())\n",
    "    z_norm = (z_series - z_series.min()) / (z_series.max() - z_series.min())\n",
    "    \n",
    "    # Configure and train reservoir\n",
    "    config = ReservoirConfig()\n",
    "    rc = ReservoirComputer(config, temporal=True)\n",
    "    \n",
    "    # Use first 4000 points for training\n",
    "    train_len = 4000\n",
    "    rc.fit(x_norm[:train_len], z_norm[:train_len])\n",
    "    \n",
    "    # Predict remaining points\n",
    "    z_pred = rc.predict(x_norm[train_len:])\n",
    "    \n",
    "    return z_series[train_len:], z_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Run Task I\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     x_test, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtask_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask I RMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mmean((y_pred \u001b[38;5;241m-\u001b[39m (x_test \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m*\u001b[39m (x_test \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m (x_test \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \n\u001b[1;32m      5\u001b[0m                                                 x_test \u001b[38;5;241m*\u001b[39m (x_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m (x_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m (x_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# # Run Task II  \u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# z_true, z_pred = task_2()\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(\"Task II RMSE:\", torch.sqrt(torch.mean((z_pred - z_true)**2)))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m, in \u001b[0;36mtask_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m x_norm \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (x\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train reservoir\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Generate test data\u001b[39;00m\n\u001b[1;32m     18\u001b[0m x_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 36\u001b[0m, in \u001b[0;36mReservoirComputer.fit\u001b[0;34m(self, inputs, targets, encoding)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     32\u001b[0m         inputs: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m     33\u001b[0m         targets: torch\u001b[38;5;241m.\u001b[39mTensor, \n\u001b[1;32m     34\u001b[0m         encoding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamplitude\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the reservoir computer\"\"\"\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     state_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_state_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Use pseudo-inverse for regression\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(state_matrix) \u001b[38;5;241m@\u001b[39m targets\n",
      "Cell \u001b[0;32mIn[13], line 29\u001b[0m, in \u001b[0;36mReservoirComputer._get_state_matrix\u001b[0;34m(self, inputs, encoding)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     state_matrix \u001b[38;5;241m=\u001b[39m states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstate_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run Task I\n",
    "    x_test, y_pred = task_1()\n",
    "    print(\"Task I RMSE:\", torch.sqrt(torch.mean((y_pred - (x_test - 3) * (x_test - 2) * (x_test - 1) * \n",
    "                                                x_test * (x_test + 1) * (x_test + 2) * (x_test + 3))**2)))\n",
    "    \n",
    "    # # Run Task II  \n",
    "    # z_true, z_pred = task_2()\n",
    "    # print(\"Task II RMSE:\", torch.sqrt(torch.mean((z_pred - z_true)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Visualize results from Task I\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mx_test\u001b[49m, (x_test \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m*\u001b[39m(x_test \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m(x_test \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mx_test\u001b[38;5;241m*\u001b[39m(x_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(x_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m(x_test \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_test, y_pred, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask I Results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize results from Task I\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(x_test, (x_test - 3)*(x_test - 2)*(x_test - 1)*x_test*(x_test + 1)*(x_test + 2)*(x_test + 3), label='True')\n",
    "plt.plot(x_test, y_pred, label='Predicted')\n",
    "plt.title(\"Task I Results\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize results from Task II\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(z_true, label='True')\n",
    "plt.plot(z_pred, label='Predicted')\n",
    "plt.title(\"Task II Results\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
